<!DOCTYPE html>
<html lang="en">

<head>

</head>

<head>
    <!-- Title -->
    <title>Temporal Logic Imitation: Learning Plan-Satisficing Motion Policies from Demonstrations</title>

    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="Temporal Logic Imitation: Learning Plan-Satisficing Motion Policies from Demonstrations">
    <meta name="keywords" content="Certifiable Imitation Learning, Dynamical Systems, Robot Learning">

    <!-- Bootstrap core CSS -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css" integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">
    <!-- https://fontawesome.com/cheatsheet -->
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.3.1/css/all.css" integrity="sha384-mzrmE5qonljUremFsqc01SB46JvROS7bZs3IO2EmfFsd15uHvIt+Y8vEf7N7fWAU" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css">
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-79592980-2"></script>
    <script>
        window.dataLayer = window.dataLayer || [];

        function gtag() {
            dataLayer.push(arguments);
        }
        gtag('js', new Date());

        gtag('config', 'UA-79592980-2');
    </script>

</head>


<body>
    <!-- <nav class="navbar navbar-expand-md navbar-dark fixed-top bg-dark"> -->
    <nav class="navbar navbar-expand-md fixed-top navbar-dark" style="background-color: #A31F34;">
        <a class="navbar-brand" href="#">LfD that guarantees task success despite perturbations</a>

        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarToggle">
            <span class="navbar-toggler-icon"></span>
        </button>

        <div class="collapse navbar-collapse" id="navbarToggle">
            <ul class="navbar-nav ml-auto">
                <li class="nav-item">
                    <a class="nav-link" href="#">Home</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="#Abstract">Abstract</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="#Paper">Paper</a>
                </li>              
                <li class="nav-item">
                    <a class="nav-link" href="#Teaser">Teaser</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="#Talk">Talk</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="#MoreVideos">More Videos</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="#Museum">Museum Demo</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="#Related">Related Works</a>
                </li>                  
            </ul>
        </div>
    </nav>
    <br>
    <div class="container" style="padding-top: 80px; font-size: 20px">
        <div align="center">
            <h2 class="text-center" align="center">
                Temporal Logic Imitation: Learning Plan-Satisficing Motion Policies from Demonstrations
            </h2>
            <h6>
                <a href="https://yanweiw.github.io/" target="_blank">Yanwei Wang</a>&nbsp;&nbsp;&nbsp;&nbsp;
                <a href="https://nbfigueroa.github.io/" target="_blank">Nadia Figueroa</a>&nbsp;&nbsp;&nbsp;&nbsp;                
                <a href="https://shenlirobot.github.io/" target="_blank">Shen Li</a>&nbsp;&nbsp;&nbsp;&nbsp;
                <a href="http://people.csail.mit.edu/ajshah/" target="_blank">Ankit Shah</a>&nbsp;&nbsp;&nbsp;&nbsp;
                <a href="https://interactive.mit.edu/about/people/julie" target="_blank">Julie Shah</a><br>
            </h6>
            <small>Interactive Robotics Lab</small> <br>
            <small>Massachusetts Institute of Technology</small>
        </div>
    </div><br>



         <div class="row justify-content-md-center">
             <div class="col-md-10 embed-responsive embed-responsive-16by9">
                <!-- <iframe width="560" height="315" src="figs/teaser05.mp4" title="Teaser" frameborder="0" allow="accelerometer; clipboard-write; encrypted-media; gyroscope; picture-in-picture; loop=1;" allowfullscreen></iframe> -->
                <video controls>
                    <source src="figs/teaser05.mp4" type="video/mp4">
                </video>
                <!-- <iframe width="560" height="315" src="figs/noise2ptz_teaser.mp4" title="Teaser" frameborder="0" allow="accelerometer; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe> -->
             </div>
         </div><br>


    <!-- Abstract -->
    <div class="container">
        <h4 id="Abstract" style="padding-top: 70px; margin-top: -80px; ">Abstract</h4>
        <hr>

        <div class="container" style="padding-top: 10px; font-size: 20px">
            <div align="center">
                <div class="center">
                    <img class="img-responsive img-rounded" src="figs/problem.png" style="width:90%" alt="">
                </div>
            </div>
        </div><br>

        <div style="text-align: justify">
            Learning from demonstration (LfD) has succeeded in tasks featuring a long time horizon. However, when the problem complexity also includes human-in-the-loop perturbations, state-of-the-art approaches do not guarantee the successful reproduction of a task. In this work, we identify the roots of this challenge as the failure of a learned continuous policy to satisfy the discrete plan implicit in the demonstration. By utilizing modes (rather than subgoals) as the discrete abstraction and motion policies with both mode invariance and goal reachability properties, we prove our learned continuous policy can simulate any discrete plan specified by a linear temporal logic (LTL) formula. Consequently, an imitator is
            robust to both task- and motion-level perturbations and guaranteed to achieve task success.
        </div>
    </div><br><br>

    <!-- Paper -->
    <div class="container">
        <h4 id="Paper" style="padding-top: 70px; margin-top: -80px;">Paper</h4>
        <hr>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2206.04632">
                    <papertitle>Temporal Logic Imitation: Learning Plan-Satisficing Motion Policies from Demonstrations</papertitle>
                </a><br>
                <strong>Yanwei Wang</strong>,
                Nadia Figueroa,
                Shen Li,
                Ankit Shah,
                Julie Shah
              <em><br>
              <a href="https://arxiv.org/abs/2206.04632">arxiv</a> /
              <a href="https://openreview.net/forum?id=ndYsaoyzCWv">review</a> /
              <a href="https://github.com/yanweiw/tli">code</a> /
              <a href="https://twitter.com/NewsHour/status/1610425346259619840">PBS News Coverage</a><br>
              <!-- <a href="" data-toggle="modal" data-target="#bibtex">bibtex</a><br> -->
              <strong>CoRL 2022</strong> (<strong style="color:red;">Oral</strong>, acceptance rate: 6.5%)<br>
              <strong>IROS 2023 Workshop</strong> (<strong style="color:red;">Best Student Paper</strong>, Learning Meets Model-based Methods for Manipulation and Grasping Workshop)
              </em><br>
            </td>
<!--             <div class="modal fade" id="bibtex" tabindex="-1" role="dialog" aria-labelledby="exampleModalCenterTitle" aria-hidden="true">
                <div class="modal-dialog modal-dialog-centered modal-lg" role="document">
                    <div class="modal-content">
                        <div class="modal-header">
                            <h5 class="modal-title" id="bibtex-title">bibtex</h5>
                            <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                                <span aria-hidden="true">&times;</span>
                            </button>
                        </div>
                        <div class="modal-body">
                            <pre>
                                @article{wang2022temporal,
                                  title={Temporal Logic Imitation: Learning Plan-Satisficing Motion Policies from Demonstrations},
                                  author={Wang, Yanwei and Figueroa, Nadia and Li, Shen and Shah, Ankit and Shah, Julie},
                                  journal={arXiv preprint arXiv:2206.04632},
                                  year={2022}
                                }                                }
                            </pre>
                        </div>
                    </div>
                </div>
            </div> -->
    </div><br><br>

    <!-- Video -->
    <div class="container">
        <h4 id="Teaser" style="padding-top: 30px; margin-top: -40px;">Teaser</h4>
        <hr>
        <div class="row justify-content-md-center">
            <div class="col-md-10 embed-responsive embed-responsive-16by9">
                <video controls>
                    <source src="figs/corl_teaser_small.mp4" type="video/mp4">
                </video>
            </div>
        </div>        
        <p>
        <div class="container" style="padding-top: 10px; font-size: 20px">
            <div align="center">
                <div class="center">
                    <div style="text-align: justify; width:90%; font-size: 15px">
                        Our Method (LTL-DS) inputs (1) an LTL formula that specifies all valid mode transitions for a task and (2)
                        demonstrations that successfully complete the task, and outputs (1) a task automaton that can reactively sequence
                        (2) a set of learned per-mode dynamical systems policy [SM Khansari-Zadeh 2011] to guarantee constraint satisfaction and goal reachability despite arbitrary external perturbations.
                    </div>
                    <p><br>
                    <img class="img-responsive img-rounded" src="figs/system.png" style="width:90%" alt="">
                </div>
            </div>
        </div>



    </div><br><br>

    <div class="container">
        <h4 id="Talk" style="padding-top: 30px; margin-top: -40px;">Talk</h4>
        <hr>

        <div class="container" style="padding-top: 10px; font-size: 20px">
            <div align="center">
                <div class="center">
                    <div style="text-align: justify; width:90%; font-size: 18px">
                        <b>Main Question</b>: Given a <i>discrete</i> task plan encoded by LTL that is reactive to perturbations,
                        how to ensure the plan is feasible for <i>continuous</i> policies learned from demonstrations,
                        i.e. to guarantee motion imitation satisfies LTL?
                    </div><br>
                    <div style='text-align: justify; width: 90%; font-size: 18px; color:#A31F34'>
                        <b>Main Takeaway</b>: Any arbitrary <i>discrete</i> task plan of mode sequence
                        is achievable by a <i>continuous</i> motion imitation system, if every learned per-mode
                        policy satisfies both <b>mode invariance</b> and <b>goal reachability</b>.
                    </div>
                </div>
            </div>
        </div>


        <div class="row justify-content-md-center">
            <div class="col-md-10 embed-responsive embed-responsive-16by9">
                <video controls>
                    <source src="figs/corl_oral_small.mp4" type="video/mp4">
                </video>
            </div>
        </div><br><br>     
        
        
        <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="row justify-content-md-center">
                <div style='text-align: center; width: 90%; font-size: 18px; color:#A31F34; width: 70%;' >
                    <b>How TLI (yellow box) fits in relation to prior work (gray boxes)</b>
                </div><br><br>
                <img src='figs/tli_related.jpg' style="width:70%" alt="">
            </div>
        </td><br><br>


        <div class="row">
            <div class="col-md-12">
                <ul>
                    <table class="center">
                        <tr style=font-size:15pt>
                            <td style='text-align:left; vertical-align:middle; color:#A31F34' colspan="2">
                                Generically Learned Motion Policy / Motion Policy with Stability Guarantee
                                <p>
                            </td>
                        </tr>
        
                        <tr>
                            <td>
                                <video width="90%" class="center" controls>
                                    <source src="figs/bc_policy.mp4" type="video/mp4">
                                </video>
                            </td>
        
                            <td>
                                <video width="90%" class="center" controls>
                                    <source src="figs/ds_policy.mp4" type="video/mp4">
                                </video>
                            </td>
                        </tr>
                    </table>
                    <div style="text-align: justify; width: 95%;">
                        Given a few demonstrations (red trajectories), generically learned
                        (state-based behavior cloning) motion policies do not guarantee policy rollouts
                        will always reach a goal given perturbations (on the left), while dynamical systems policy
                        (a BC-variant with G.A.S. property) guarantees goal reachability.
                    </div>
                </ul>
            </div>
        </div>
        
        <div class="row">
            <div class="col-md-12">
                <ul>
                    <table class="center">
                        <tr style=font-size:15pt>
                            <td style='text-align:left; vertical-align:middle; color:#A31F34' colspan="2">
                                Motion Policy without Mode Invariance / with Mode Invariance
                                <p>
                            </td>
                        </tr>
        
                        <tr>
                            <td>
                                <video width="90%" class="center" controls>
                                    <source src="figs/no_mod_stuck.mp4" type="video/mp4">
                                </video>
                            </td>
        
                            <td>
                                <video width="90%" class="center" controls>
                                    <source src="figs/with_mod_no_stuck.mp4" type="video/mp4">
                                </video>
                            </td>
                        </tr>
                    </table>
                    <div style="text-align: justify; width: 95%;">
                        The task is to transition through the white, yellow, pink,
                        and green regions consecutively. The pink region can only be entered from the
                        yellow region, and the green region can only be entered from the pink region.
                        Motion policies without mode invariance<i>-the property that policy rollouts
                            do not leave a mode prematurely-</i>lead to looping despite LTL'reactivity
                        (on the left), while motion policies with mode invariance (achieved by boundary
                        estimation and modulation) ensure both constraint satisfaction and goal reachability.
                    </div>
                </ul>
            </div>
        </div>
        
        
        <div class="row">
            <div class="col-md-12">
                <ul>
                    <table class="center">
                        <tr style=font-size:15pt>
                            <td style='text-align:left; vertical-align:middle; color:#A31F34' colspan="2">
                                Iterative Boundary Estimation of Unknown Mode with Cutting Planes
                                <p>
                            </td>
                        </tr>
        
                        <tr>
                            <td width="50%">
                                <video width="90%" class="center" controls>
                                    <source src="figs/boundary_estimation.mp4" type="video/mp4">
                                </video>
                            </td>
                            <td>
                                <div style="text-align: justify; width: 90%;">
                                    To modulate motion policies so that they become mode-invariant,
                                    unknown mode boundary is first estimated. Invariance failures detected by sensors
                                    are used to find cutting planes that bound the mode within which DS flows are modulated
                                    to stay.
                                    Note flows that have left the mode will re-enter the mode due to LTL's reactivity,
                                    and iteratively increasingly better boundary estimation is attained.
                                </div>
                            </td>
                        </tr>

                    </table>
                </ul>
            </div>
        </div>

    </div><br><br>

    <div class="container">
        <h4 id="MoreVideos" style="padding-top: 30px; margin-top: -40px;">More Videos</h4>
        <hr>


        <div class="row">
            <div class="col-md-12">
                <ul>
                    <table class="center">
                        <tr style=font-size:15pt>
                            <td style='text-align:center; vertical-align:middle; color:#A31F34' colspan="4">
                                Generalization to New Tasks by Reusing Learned Skills
                                <p>
                            </td>
                        </tr>
                        <tr>
                            <td width="25%">
                                <video width="90%" class="center" controls>
                                    <source src="figs/get_chicken_first.mp4" type="video/mp4">
                                </video>
                            </td>        
                            <td width="25%">
                                <video width="90%" class="center" controls>
                                    <source src="figs/get_broccoli_first.mp4" type="video/mp4">
                                </video>
                            </td>
                            <td width="25%">
                                <video width="90%" class="center" controls>
                                    <source src="figs/getting_only_chicken.mp4" type="video/mp4">
                                </video>
                            </td>
                            <td width="25%">
                                <video width="90%" class="center" controls>
                                    <source src="figs/continuously_getting_chicken.mp4" type="video/mp4">
                                </video>
                            </td>
                        </tr>
                    </table>
                    <div style="text-align: justify; width: 98%;">
                        LTL-DS generalizes to new task structures (encoded by LTL) by flexibly combining individual skills learned in
                        demonstrations. Consider a demonstration of adding chicken (visiting the yellow region) and then broccoli (visiting the
                        green region) to a pot (visiting the gray region). After individual DS of visiting the yellow, the green, and the gray
                        region are learned, they can be recombined given a new LTL (refer to the paper) to solve new tasks such as (1) adding
                        broccoli and then chicken, (2) adding only chicken, (3) continuously adding chicken. Note the white region represents an
                        empty spoon and crossing from yellow/green to white means spilling the food.
                    </div>
                </ul>
            </div>
        </div><br>

        <div class="row">
            <div class="col-md-12">
                <ul>
                    <table class="center">
                        <tr style=font-size:15pt>
                            <td style='text-align:center; vertical-align:middle; color:#A31F34' colspan="4">
                                Line Inspection Task
                                <p>
                            </td>
                        </tr>
                        <tr>
                            <td>
                                <video width="100%" class="center" controls>
                                    <source src="figs/exp2.mp4" type="video/mp4">
                                </video>
                            </td>
                        </tr>
                    </table>
                </ul>
            </div>
        </div><br>

        <div class="row">
            <div class="col-md-12">
                <ul>
                    <table class="center">
                        <tr style=font-size:15pt>
                            <td style='text-align:center; vertical-align:middle; color:#A31F34' colspan="4">
                                Color Tracing Task
                                <p>
                            </td>
                        </tr>
                        <tr>
                            <td>
                                <video width="100%" class="center" controls>
                                    <source src="figs/exp3.mp4" type="video/mp4">
                                </video>
                            </td>
                        </tr>
                    </table>
                </ul>
            </div>
        </div><br>

        <div class="row">
            <div class="col-md-12">
                <ul>
                    <table class="center">
                        <tr style=font-size:15pt>
                            <td style='text-align:center; vertical-align:middle; color:#A31F34' colspan="4">
                                Scooping Task
                                <p>
                            </td>
                        </tr>
                        <tr>
                            <td>
                                <video width="100%" class="center" controls>
                                    <source src="figs/exp1_human_perturb.mp4" type="video/mp4">
                                </video>
                            </td>
                        </tr>
                    </table>
                </ul>
            </div>
        </div><br>
    </div><br>

    <div class="container">
        <h4 id="Museum" style="padding-top: 30px; margin-top: -40px;">MIT Museum Demo</h4>
        <hr>
        <div class="row justify-content-md-center">
            <table>
                <tr style=font-size:15pt><td style='text-align:center; vertical-align:middle; color:#A31F34' colspan="1">A permanent interactive exhibition at <a href="https://mitmuseum.mit.edu/">MIT museum</a> of programming robots via demonstrations<p></td></tr><br>
            </table>
            <div class="col-md-10 embed-responsive embed-responsive-16by9">
                <video controls>
                    <source src="figs/MIT_Museum_DS_Demo.mp4#t=90" type="video/mp4">
                </video>
            </div>
        </div>        
    </div><br><br><br>


    <!-- Poster -->
    <div class="container">
        <h4 id="Related" style="padding-top: 30px; margin-top: -40px;">Related Works - Extending TLI by Learning instead of Engineering Sensor Models</h4>
        <hr>
        <!-- <img class="img-responsive img-rounded" src="figs/tli_hill_poster.png" style="width:100%" alt=""> -->
        <!-- <div class="row justify-content-md-center">
            <iframe src="figs/tli_hill_poster.pdf" width="100%" height="500px"></iframe>
        </div> -->

        <table class="center">
            <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                    <img src='figs/scoop.jpg' width="300">
                </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2403.17124">
                    <papertitle>Grounding Language Plans in Demonstrations through Counterfactual Perturbations</papertitle>
                </a>
                <br>
                <strong>Yanwei Wang</strong>,
                Tsun-Hsuan Wang,
                Jiayuan Mao,
                Michael Hagenow,
                Julie Shah
                <em><br>
                    <a href="https://arxiv.org/abs/2403.17124">paper</a>
                    /
                    <a href="https://sites.google.com/view/grounding-plans">project page</a>
                    <br>
                    <strong>ICLR 2024</strong> (<strong style="color:red;">Spotlight</strong>, acceptance rate: 5%)
                </em><br>
                <p>This work learns grounding classifiers for LLM planning. By locally perturbing a few human demonstrations, we
                    augment
                    the dataset with more successful executions and failing counterfactuals. Our end-to-end explanation-based
                    network is
                    trained to differentiate successes from failures and as a by-product learns classifiers that ground continuous
                    states
                    into discrete manipulation mode families without dense labeling.</p>
            </td>
        </table>


    </div><br><br>

    <!-- Bootstrap core JavaScript -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.11.0/umd/popper.min.js" integrity="sha384-b/U6ypiBEHpOf/4+1nzFpr53nxSS+GLCkfwBdFNTxtclqqenISfwAzpKaMNFNmj4" crossorigin="anonymous"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta/js/bootstrap.min.js" integrity="sha384-h0AbiXch4ZDo7tp9hKZ4TsHbi047NrKGLO3SEJAg45jXxnGIfYzk4Si90RDIqNm1" crossorigin="anonymous"></script>

</body>

</html>